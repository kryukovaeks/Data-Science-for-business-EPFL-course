{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSFB Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will begin to work with text data and natural language processing. You will analyze aspects of th DonorsChoose.org program. Aspects of this project were first posed as a Kaggle challenge and the data comes from [Kaggle DonorsChoose.org Application Screening challenge](https://www.kaggle.com/c/donorschoose-application-screening/data). We have changed the nature of what you need to do in this assignment (so it does not track what was done in the Kaggle Challenge), but nevertheless using or referring to the Kaggle Challenge repository is not allowed for the assignment.\n",
    "\n",
    "###  DonorsChoose.org  \n",
    "  \n",
    "Founded in 2000 by a high school teacher in the Bronx, DonorsChoose.org empowers public school teachers from across the country to request much-needed materials and experiences for their students. At any given time, there are thousands of classroom requests that can be brought to life with a gift of any amount. DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website. In this assignment, you will analyze the text of the essays and requirements from each proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cached.imagescaler.hbpl.co.uk/resize/scaleWidth/580/cached.offlinehbpl.hbpl.co.uk/news/NST/C8B9CC1D-03B0-9B80-4CFE78B5B539240F.jpg\" width=\"500\" height=\"500\" align=\"center\"/>\n",
    "\n",
    "Image source: https://cached.imagescaler.hbpl.co.uk/resize/scaleWidth/580/cached.offlinehbpl.hbpl.co.uk/news/NST/C8B9CC1D-03B0-9B80-4CFE78B5B539240F.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, this dataset includes many different kinds of features with structured and unstructured data. The dataset consists of application materials (see *application_data.csv*) and resources requested (see *resource_data.csv*). The application materials (see *application_data.csv*) contain the following features.\n",
    "\n",
    "| Feature name  | Description  |\n",
    "|----------------|--------------|\n",
    "| id  | Unique id of the project application    |\n",
    "| teacher_id    | id of the teacher submitting the application  |\n",
    "| teacher_prefix    | title of the teacher's name (Ms., Mr., etc.)    |\n",
    "| school_state    | US state of the teacher's school    |\n",
    "| project_submitted_datetime    | application submission timestamp    |\n",
    "| project_grade_category    | school grade levels (PreK-2, 3-5, 6-8, and 9-12)   |\n",
    "| project_subject_categories   | category of the project (e.g., \"Music & The Arts\")    |\n",
    "| project_subject_subcategories    | sub-category of the project (e.g., \"Visual Arts\")    |\n",
    "| project_title    | title of the project    |\n",
    "| project_essay_1    | first essay*   |\n",
    "| project_essay_2    | second essay*    |\n",
    "| project_essay_3    | third essay*   |\n",
    "| project_essay_4    | fourth essay*  |\n",
    "| project_resource_summary    | summary of the resources needed for the project    |\n",
    "| teacher_number_of_previously_posted_projects   | number of previously posted applications by the submitting teacher    |\n",
    "| project_is_approved    | whether DonorsChoose proposal was accepted (0=\"rejected\", 1=\"accepted\"); train.csv only    |\n",
    "\n",
    "\n",
    "\\*Note: Prior to May 17, 2016, the prompts for the essays were as follows:\n",
    "\n",
    "  * project_essay_1: \"Introduce us to your classroom\"  \n",
    "\n",
    "  * project_essay_2: \"Tell us more about your students\"  \n",
    "\n",
    "  * project_essay_3: \"Describe how your students will use the materials you're requesting\"  \n",
    "\n",
    "  * project_essay_4: \"Close by sharing why your project will make a difference\"  \n",
    "\n",
    "Starting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:\n",
    "\n",
    "  * project_essay_1: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"  \n",
    "\n",
    "  * project_essay_2: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"  \n",
    "\n",
    "For all projects with project_submitted_datetime of 2016-05-17 and later, the values of project_essay_3 and project_essay_4 will be missing (i.e. NaN).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special NLP Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several new libraries for this assignment - so be sure to first install those on your machine by with `pip` in a terminal:\n",
    "\n",
    "    pip install --user -U nltk\n",
    "    pip install -U gensim\n",
    "    pip install -U spacy\n",
    "    pip install -U pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math  \n",
    "import copy\n",
    "\n",
    "from pprint import pprint  # nicer printing\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Other NLP\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# General Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Special Plotting\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "\n",
    "# ignore some warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the maximum number of rows displayed by pandas\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "# Set some CONSTANTS that will be used later\n",
    "SEED    = 41  # base to generate a random number\n",
    "SCORE   = 'roc_auc'\n",
    "FIGSIZE = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To use a particular model in the `spacy` package, you need to manually download and install that particular model. You will need to run the following code from a terminal: `python -m spacy download en_core_web_sm`. Rather than doing that manually from bash in a separate terminal program, do it inline below using a \"magic\" command in jupyter. HINT: Use *!* followed by a bash command in a cell to run a bash command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from en_core_web_sm==2.3.1) (2.3.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.2.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0; python_version >= \"3.6\" in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.54.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Download en_core_web_sm for spacy\n",
    "\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To confirm that `spacy` is working (and `en_core_web_sm` is installed on your computer), you should be able to use `spacy.load()` to build a `Language` object to perform some basic nlp. Do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test use of spacy by using the spacy.load() function\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use nltk.download() to download a list of raw stopwords. (see NLTK documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ekaterinakryukova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use the `stopwords` object from `nltk` to build a list of English stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English Stopwords from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Extend your `stop_words` list with some additional stopwords that you believe should be ignored in this particular context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "# Extend the stop word list  \n",
    "\n",
    "stopWords.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other projects, this project includes a training set too big for GitHub. Through the terminal lab of Jupyter lab, download the data using the *wget* command, unzip it using the *zip* command and check that it's in the root directory of the project. \n",
    "\n",
    "Locations : \n",
    "\n",
    "    Applications dataset: https://storage.googleapis.com/dsfm-datasets/text-applications/application_data.csv.zip\n",
    "    Resources dataset: https://storage.googleapis.com/dsfm-datasets/text-applications/resource_data.csv.zip\n",
    "    \n",
    "Hint: Use *wget* and *unzip* commands. Use *!* followed by a bash command in a cell to run a bash command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: wget the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/application_data.csv (1).zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wget the data\n",
    "import wget\n",
    "wget.download('https://storage.googleapis.com/dsfm-datasets/text-applications/application_data.csv.zip','data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/resource_data.csv (1).zip'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download('https://storage.googleapis.com/dsfm-datasets/text-applications/resource_data.csv.zip','data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "from zipfile import ZipFile\n",
    "zip = ZipFile('data/application_data.csv.zip')\n",
    "zip.extractall('data/application_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zip = ZipFile('data/resource_data.csv.zip')\n",
    "zip.extractall('data/resource_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Load `application_data.csv` and investigate it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p233823</td>\n",
       "      <td>a9b876a9252e08a55e3d894150f75ba3</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>Lets 3Doodle to Learn</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>We are looking to add some 3Doodler to our cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need the 3doodler. We are an SEM s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p185307</td>\n",
       "      <td>525fdbb6ec7f538a48beebaa0a51b24f</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>\\\"Kid Inspired\\\" Equipment to Increase Activit...</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>The student's project which is totally \\\"kid-i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need balls and other activity equi...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p013780</td>\n",
       "      <td>a63b5547a7239eae4c1872670848e61a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>We need clean water for our culinary arts class!</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>For some reason in our kitchen the water comes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a water filtration system for...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
       "3  p185307  525fdbb6ec7f538a48beebaa0a51b24f            Mr.           NC   \n",
       "4  p013780  a63b5547a7239eae4c1872670848e61a            Mr.           CA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2   \n",
       "1        2017-04-26 15:57:28             Grades 3-5   \n",
       "2        2017-01-01 22:57:44             Grades 3-5   \n",
       "3        2016-08-12 15:42:11             Grades 3-5   \n",
       "4        2016-08-06 09:09:11             Grades 6-8   \n",
       "\n",
       "            project_subject_categories  \\\n",
       "0                  Literacy & Language   \n",
       "1    Music & The Arts, Health & Sports   \n",
       "2  Math & Science, Literacy & Language   \n",
       "3                      Health & Sports   \n",
       "4                      Health & Sports   \n",
       "\n",
       "            project_subject_subcategories  \\\n",
       "0                                Literacy   \n",
       "1            Performing Arts, Team Sports   \n",
       "2  Applied Sciences, Literature & Writing   \n",
       "3                       Health & Wellness   \n",
       "4                       Health & Wellness   \n",
       "\n",
       "                                       project_title  \\\n",
       "0                           Super Sight Word Centers   \n",
       "1                             Keep Calm and Dance On   \n",
       "2                              Lets 3Doodle to Learn   \n",
       "3  \\\"Kid Inspired\\\" Equipment to Increase Activit...   \n",
       "4   We need clean water for our culinary arts class!   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3  My students are the greatest students but are ...   \n",
       "4  My students are athletes and students who are ...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
       "3  The student's project which is totally \\\"kid-i...             NaN   \n",
       "4  For some reason in our kitchen the water comes...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
       "3             NaN  My students need balls and other activity equi...   \n",
       "4             NaN  My students need a water filtration system for...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
       "0                                            26                    1  \n",
       "1                                             1                    0  \n",
       "2                                             5                    1  \n",
       "3                                            16                    0  \n",
       "4                                            42                    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load applications\n",
    "application_data = pd.read_csv('data/application_data/application_data.csv',parse_dates=['project_submitted_datetime'])\n",
    "application_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type of date column\n",
    "application_data.project_submitted_datetime.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 175706, 175706)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of nan values\n",
    "application_data.project_essay_1.isna().sum(),application_data.project_essay_2.isna().sum(),application_data.project_essay_3.isna().sum(),application_data.project_essay_4.isna().sum(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Load `resource_data.csv` and investigate it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Cory Stories: A Kid's Book About Living With Adhd</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...</td>\n",
       "      <td>2</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p069063</td>\n",
       "      <td>EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...</td>\n",
       "      <td>3</td>\n",
       "      <td>24.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
       "3  p069063  Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...         2   \n",
       "4  p069063  EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...         3   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  \n",
       "2    8.45  \n",
       "3   13.59  \n",
       "4   24.95  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load resources\n",
    "\n",
    "resource_data = pd.read_csv('data/resource_data/resource_data.csv')\n",
    "resource_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Some of the essays are NA. Replace NAs with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace NA values in essay columns with ''\n",
    "\n",
    "application_data[['project_essay_3','project_essay_4']]=application_data[['project_essay_3',\n",
    "                  'project_essay_4']].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count nan\n",
    "application_data.project_essay_1.isna().sum(),application_data.project_essay_2.isna().sum(),application_data.project_essay_3.isna().sum(),application_data.project_essay_4.isna().sum(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_essay_1', 'project_essay_2',\n",
       "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: To simplify matters, combine all essays into just one feature called \"essays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine essays\n",
    "application_data['essays']=application_data['project_essay_{}'.format(1)]\n",
    "for i in range(2,5):\n",
    "    application_data['essays']+=application_data['project_essay_{}'.format(i)].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>p232007</td>\n",
       "      <td>e7a8f866e3174a77ffe37323f032a8ac</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-27 09:58:04</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Applied Learning, Literacy &amp; Language</td>\n",
       "      <td>College &amp; Career Prep, Literature &amp; Writing</td>\n",
       "      <td>Watch Readers Grow!</td>\n",
       "      <td>During our reading workshop students are at da...</td>\n",
       "      <td>My students lack confidence. I have a class wi...</td>\n",
       "      <td>During our reading workshop. We do mini lesson...</td>\n",
       "      <td>Your donations would greatly be a blessing for...</td>\n",
       "      <td>My students need these reading materials to he...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>During our reading workshop students are at da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                        teacher_id teacher_prefix school_state  \\\n",
       "18  p232007  e7a8f866e3174a77ffe37323f032a8ac           Mrs.           FL   \n",
       "\n",
       "   project_submitted_datetime project_grade_category  \\\n",
       "18        2016-04-27 09:58:04          Grades PreK-2   \n",
       "\n",
       "               project_subject_categories  \\\n",
       "18  Applied Learning, Literacy & Language   \n",
       "\n",
       "                  project_subject_subcategories        project_title  \\\n",
       "18  College & Career Prep, Literature & Writing  Watch Readers Grow!   \n",
       "\n",
       "                                      project_essay_1  \\\n",
       "18  During our reading workshop students are at da...   \n",
       "\n",
       "                                      project_essay_2  \\\n",
       "18  My students lack confidence. I have a class wi...   \n",
       "\n",
       "                                      project_essay_3  \\\n",
       "18  During our reading workshop. We do mini lesson...   \n",
       "\n",
       "                                      project_essay_4  \\\n",
       "18  Your donations would greatly be a blessing for...   \n",
       "\n",
       "                             project_resource_summary  \\\n",
       "18  My students need these reading materials to he...   \n",
       "\n",
       "    teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "18                                             6                    1   \n",
       "\n",
       "                                               essays  \n",
       "18  During our reading workshop students are at da...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data with all essays\n",
    "application_data[application_data.project_submitted_datetime<'2016-05-17'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During our reading workshop students are at daily 5. My students need activities to help them practice skills in a fun and enjoyable way that is on the level of each child. As the teacher I enjoy conferencing with each student, so the more engaged the students are practicing the skills they.My students lack confidence. I have a class with such great potential. My students need more hands on learning and extra practice to catch and grow a love for reading. My second graders love to learn. We have resources but most are out dated. My students would be so bright if they could only build confidence. I believe in them and now I want to see them bloom.During our reading workshop. We do mini lessons that focus on a skill and then they rotate through daily 5 (centers). These reading activities will help them apply what they learned and reinforce the skills. They rotate through self read, buddy read (carpet) listening, writing,  word work (reading skills). If the class is actively engaged this leave more time for small group learning and conferencing with students. The giant magnet words will help at word work to build sentences and use the correct parts of speech. The classroom carpet will be for read to self where students can cozy up with a good book. Read with a pen close reads will be used during buddy read where students can zoom into the meanings and what is being read. The language skill center and quick picks will be used for our writing center and will help students with the skills they need to be great writers. All these materials will help my students grow doing our daily readers workshop.Your donations would greatly be a blessing for all my students. They focus on all the daily 5 rotations as well as help them grow. These reading activities will keep students engaged so the teacher can work and help students master the skills they are week in. The reading genre carpet will be used to enjoy a cozy place to sit and read. The close reads will be at buddy read so that students can help each other focus on what is being read. Thank you in advance for helping them grow as reader.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "application_data['essays'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During our reading workshop students are at daily 5. My students need activities to help them practice skills in a fun and enjoyable way that is on the level of each child. As the teacher I enjoy conferencing with each student, so the more engaged the students are practicing the skills they.\n",
      "My students lack confidence. I have a class with such great potential. My students need more hands on learning and extra practice to catch and grow a love for reading. My second graders love to learn. We have resources but most are out dated. My students would be so bright if they could only build confidence. I believe in them and now I want to see them bloom.\n",
      "During our reading workshop. We do mini lessons that focus on a skill and then they rotate through daily 5 (centers). These reading activities will help them apply what they learned and reinforce the skills. They rotate through self read, buddy read (carpet) listening, writing,  word work (reading skills). If the class is actively engaged this leave more time for small group learning and conferencing with students. The giant magnet words will help at word work to build sentences and use the correct parts of speech. The classroom carpet will be for read to self where students can cozy up with a good book. Read with a pen close reads will be used during buddy read where students can zoom into the meanings and what is being read. The language skill center and quick picks will be used for our writing center and will help students with the skills they need to be great writers. All these materials will help my students grow doing our daily readers workshop.\n",
      "Your donations would greatly be a blessing for all my students. They focus on all the daily 5 rotations as well as help them grow. These reading activities will keep students engaged so the teacher can work and help students master the skills they are week in. The reading genre carpet will be used to enjoy a cozy place to sit and read. The close reads will be at buddy read so that students can help each other focus on what is being read. Thank you in advance for helping them grow as reader.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(application_data['project_essay_{}'.format(i)][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#drop separate columns of essays\n",
    "for i in range(1,5):\n",
    "    application_data.drop(columns=['project_essay_{}'.format(i)],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'essays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'essays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'description', 'quantity', 'price'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Merge the resources and application datasets on the *id* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'essays', 'description', 'quantity', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge two datasets\n",
    "\n",
    "\n",
    "merged_df=application_data.merge(resource_data, on='id', how='inner')\n",
    "# Check the data to confirm it worked\n",
    "\n",
    "merged_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Keep the following data for additional analysis (the id and the text features): `id`, `school_state`, `project_subject_categories`, `project_subject_subcategories`, `essays`, `description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = ['school_state', 'project_subject_categories', 'project_subject_subcategories', 'essays', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the Text Featuresss\n",
    "\n",
    "merged_df_textual=merged_df[['id']+FEATURE_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple - iPod nano� 16GB MP3 Player (8th Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple - iPod nano� 16GB MP3 Player (8th Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p039565</td>\n",
       "      <td>GA</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>Reebok Girls' Fashion Dance Graphic T-Shirt - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p233823</td>\n",
       "      <td>UT</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>3doodler Start Full Edu Bundle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p185307</td>\n",
       "      <td>NC</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>BALL PG 4'' POLY SET OF 6 COLORS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id school_state           project_subject_categories  \\\n",
       "0  p036502           NV                  Literacy & Language   \n",
       "1  p036502           NV                  Literacy & Language   \n",
       "2  p039565           GA    Music & The Arts, Health & Sports   \n",
       "3  p233823           UT  Math & Science, Literacy & Language   \n",
       "4  p185307           NC                      Health & Sports   \n",
       "\n",
       "            project_subject_subcategories  \\\n",
       "0                                Literacy   \n",
       "1                                Literacy   \n",
       "2            Performing Arts, Team Sports   \n",
       "3  Applied Sciences, Literature & Writing   \n",
       "4                       Health & Wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Most of my kindergarten students come from low...   \n",
       "2  Our elementary school is a culturally rich sch...   \n",
       "3  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "4  My students are the greatest students but are ...   \n",
       "\n",
       "                                         description  \n",
       "0  Apple - iPod nano� 16GB MP3 Player (8th Genera...  \n",
       "1  Apple - iPod nano� 16GB MP3 Player (8th Genera...  \n",
       "2  Reebok Girls' Fashion Dance Graphic T-Shirt - ...  \n",
       "3                     3doodler Start Full Edu Bundle  \n",
       "4                   BALL PG 4'' POLY SET OF 6 COLORS  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_textual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Preprocess Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an independent copy of the data so we can restart here when testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.copy(merged_df_textual)  # when \"merged\" is the pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Define a custom function `clean_punctuation()` to remove some punctuation from your text data. You don't have to do absolutely everything one might want to do - just show that you can do it. Start with each some easy operations with `str.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean punctuation from  given text\n",
    "\n",
    "def clean_punctuation(txt):\n",
    "    txt=txt.replace('&', ' ')\n",
    "    txt=txt.replace('.', ' ')\n",
    "    txt=txt.replace(\"\\\\r\\\\n\", \" \")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Use the `apply()` function from pandas to _apply_ that function down the `essays` column of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy   Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple - iPod nano� 16GB MP3 Player (8th Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy   Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple - iPod nano� 16GB MP3 Player (8th Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p039565</td>\n",
       "      <td>GA</td>\n",
       "      <td>Music   The Arts, Health   Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>Reebok Girls' Fashion Dance Graphic T-Shirt - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p233823</td>\n",
       "      <td>UT</td>\n",
       "      <td>Math   Science, Literacy   Language</td>\n",
       "      <td>Applied Sciences, Literature   Writing</td>\n",
       "      <td>Hello; My name is Mrs  Brotherton  I teach 5th...</td>\n",
       "      <td>3doodler Start Full Edu Bundle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p185307</td>\n",
       "      <td>NC</td>\n",
       "      <td>Health   Sports</td>\n",
       "      <td>Health   Wellness</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>BALL PG 4'' POLY SET OF 6 COLORS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id school_state           project_subject_categories  \\\n",
       "0  p036502           NV                  Literacy   Language   \n",
       "1  p036502           NV                  Literacy   Language   \n",
       "2  p039565           GA    Music   The Arts, Health   Sports   \n",
       "3  p233823           UT  Math   Science, Literacy   Language   \n",
       "4  p185307           NC                      Health   Sports   \n",
       "\n",
       "            project_subject_subcategories  \\\n",
       "0                                Literacy   \n",
       "1                                Literacy   \n",
       "2            Performing Arts, Team Sports   \n",
       "3  Applied Sciences, Literature   Writing   \n",
       "4                       Health   Wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Most of my kindergarten students come from low...   \n",
       "2  Our elementary school is a culturally rich sch...   \n",
       "3  Hello; My name is Mrs  Brotherton  I teach 5th...   \n",
       "4  My students are the greatest students but are ...   \n",
       "\n",
       "                                         description  \n",
       "0  Apple - iPod nano� 16GB MP3 Player (8th Genera...  \n",
       "1  Apple - iPod nano� 16GB MP3 Player (8th Genera...  \n",
       "2  Reebok Girls' Fashion Dance Graphic T-Shirt - ...  \n",
       "3                     3doodler Start Full Edu Bundle  \n",
       "4                   BALL PG 4'' POLY SET OF 6 COLORS  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply your function to clean the essays column\n",
    "for feature in ['school_state', 'project_subject_categories', 'project_subject_subcategories', 'essays']:\n",
    "    data[feature]=data[feature].apply(clean_punctuation)\n",
    "    \n",
    "    \n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Define **another** custom function called `clean_re()` to clean your text data using regular expressions. Do at least two \"cleanings\" (i.e., show that you can use the `re` library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to clean some given text\n",
    "import re\n",
    "\n",
    "def clean_re(txt):\n",
    "    p = re.compile(r'[^\\w\\s]')\n",
    "    txt=p.sub('', txt)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>essays</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy   Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple  iPod nano 16GB MP3 Player 8th Generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p036502</td>\n",
       "      <td>NV</td>\n",
       "      <td>Literacy   Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>Apple  iPod nano 16GB MP3 Player 8th Generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p039565</td>\n",
       "      <td>GA</td>\n",
       "      <td>Music   The Arts Health   Sports</td>\n",
       "      <td>Performing Arts Team Sports</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>Reebok Girls Fashion Dance Graphic TShirt  Dd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p233823</td>\n",
       "      <td>UT</td>\n",
       "      <td>Math   Science Literacy   Language</td>\n",
       "      <td>Applied Sciences Literature   Writing</td>\n",
       "      <td>Hello My name is Mrs  Brotherton  I teach 5th ...</td>\n",
       "      <td>3doodler Start Full Edu Bundle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p185307</td>\n",
       "      <td>NC</td>\n",
       "      <td>Health   Sports</td>\n",
       "      <td>Health   Wellness</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>BALL PG 4 POLY SET OF 6 COLORS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id school_state          project_subject_categories  \\\n",
       "0  p036502           NV                 Literacy   Language   \n",
       "1  p036502           NV                 Literacy   Language   \n",
       "2  p039565           GA    Music   The Arts Health   Sports   \n",
       "3  p233823           UT  Math   Science Literacy   Language   \n",
       "4  p185307           NC                     Health   Sports   \n",
       "\n",
       "           project_subject_subcategories  \\\n",
       "0                               Literacy   \n",
       "1                               Literacy   \n",
       "2            Performing Arts Team Sports   \n",
       "3  Applied Sciences Literature   Writing   \n",
       "4                      Health   Wellness   \n",
       "\n",
       "                                              essays  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Most of my kindergarten students come from low...   \n",
       "2  Our elementary school is a culturally rich sch...   \n",
       "3  Hello My name is Mrs  Brotherton  I teach 5th ...   \n",
       "4  My students are the greatest students but are ...   \n",
       "\n",
       "                                         description  \n",
       "0  Apple  iPod nano 16GB MP3 Player 8th Generatio...  \n",
       "1  Apple  iPod nano 16GB MP3 Player 8th Generatio...  \n",
       "2  Reebok Girls Fashion Dance Graphic TShirt  Dd ...  \n",
       "3                     3doodler Start Full Edu Bundle  \n",
       "4                     BALL PG 4 POLY SET OF 6 COLORS  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply clean_re() to all features\n",
    "\n",
    "for feature in FEATURE_NAMES:\n",
    "    data[feature]=data[feature].astype(str).apply(clean_re)\n",
    "    \n",
    "    \n",
    "    \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Apple  iPod nano 16GB MP3 Player 8th Generatio...\n",
       "1    Apple  iPod nano 16GB MP3 Player 8th Generatio...\n",
       "2    Reebok Girls Fashion Dance Graphic TShirt  Dd ...\n",
       "3                       3doodler Start Full Edu Bundle\n",
       "4                       BALL PG 4 POLY SET OF 6 COLORS\n",
       "5                     BALL PLAYGROUND POLY 85 SET OF 6\n",
       "6                            KIT JUMBO GRADESTUFF PACK\n",
       "7                           PARACHUTE GRIPSTARCHUTE 24\n",
       "8                           RECESS PACK GRADE K VIOLET\n",
       "9    Crown Berkey Water Filter With 2 Black and 2 P...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Remove stopwords. (Hint: use stopwords from nltk's `stopwords()` plus any additions you'd like to make. Then, again, define a custom function and then apply it to all features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "stopWords.extend(['although','engaging','approximately','yet','nan','u','us','would','would','see','big','student'])\n",
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to remove stopwords\n",
    "df = copy.copy(data)  \n",
    "def clean_stopword(txt):\n",
    "    txt=txt.lower().split()\n",
    "    filtered_sentence = [w for w in txt if  w  not in  stopWords]  \n",
    "    filtered_sentence=' '.join(filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ee032ca4310f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply function to remove stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFEATURE_NAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stopword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1ffb4bda93d2>\u001b[0m in \u001b[0;36mclean_stopword\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_stopword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32mif\u001b[0m  \u001b[0mw\u001b[0m  \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mstopWords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1ffb4bda93d2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_stopword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;32mif\u001b[0m  \u001b[0mw\u001b[0m  \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mstopWords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply function to remove stopwords  \n",
    "for feature in FEATURE_NAMES:\n",
    "    df[feature]=df[feature].apply(clean_stopword)\n",
    "    \n",
    "    \n",
    "    \n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Now use Gensim’s `simple_preprocess()` function to tokenize and clean up your text data. TIP: `simple_preprocess()` returns a list of words, so we want to wrap it with a function that joins the list back together into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to wrap c from gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "df2 = copy.copy(df) \n",
    "def simple_preprocess_custom(txt):\n",
    "    txt=simple_preprocess(txt)\n",
    "    txt=' '.join(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply simple_preprocess() to all features\n",
    "\n",
    "for feature in FEATURE_NAMES:\n",
    "    df2[feature]=df2[feature].apply(simple_preprocess_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: Lemmatize the text. (Hint: Define a custom function and then apply it to all features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a lemmatization function based on nltk.stem.WordNetLemmatizer()\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "df3=copy.copy(df2)\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def get_pos( word ):\n",
    "    w_synsets = wordnet.synsets(word)\n",
    "\n",
    "    pos_counts = Counter()\n",
    "    pos_counts[\"n\"] = len(  [ item for item in w_synsets if item.pos()==\"n\"]  )\n",
    "    pos_counts[\"v\"] = len(  [ item for item in w_synsets if item.pos()==\"v\"]  )\n",
    "    pos_counts[\"a\"] = len(  [ item for item in w_synsets if item.pos()==\"a\"]  )\n",
    "    pos_counts[\"r\"] = len(  [ item for item in w_synsets if item.pos()==\"r\"]  )\n",
    "    \n",
    "    most_common_pos_list = pos_counts.most_common(3)\n",
    "    return most_common_pos_list[0][0]\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text=[lemmatizer.lemmatize(w,get_pos(w)) for w in w_tokenizer.tokenize(text)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply lemmatize_text() to all features  \n",
    "from tqdm import tqdm\n",
    "for feature in tqdm(['essays','description']):\n",
    "    df3[feature]=df3[feature].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM**: What happened to the data in the pandas dataframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: It was converted from long text into a list of individual words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4:  Make an LDA topic model for the ESSAYS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Part 4 is worth 10 points (the value of 10 individual problems).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an LDA topic model for the `essays`. Compute the \"Coherence score.\" Visually inspect the topic model by inspecting the top keywords from each model. Gensim provides functions for all of these tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df3['essays'])\n",
    "\n",
    "# Create Corpus\n",
    "texts = df3['essays']\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View unique id for each word in the essay\n",
    "print(corpus[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View word a given id corresponds to for id=0\n",
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.project_subject_categories.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build LDA model --too long\n",
    "\"\"\"lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=13, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "##\n",
    "## Build Multicore LDA\n",
    "lda_multicore_model = gensim.models.ldamulticore.LdaMulticore(corpus, num_topics = 7, id2word=id2word,random_state=100,passes=10)\n",
    "# Saving trained model\n",
    "lda_multicore_model.save('LDA_NYT_multicore')\n",
    "# Loading trained model\n",
    "lda_multicore_model = gensim.models.ldamodel.LdaModel.load('LDA_NYT_multicore')\n",
    "## Print time taken to train the model\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3['essays'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 7 topics\n",
    "print(lda_multicore_model.print_topics())\n",
    "doc_lda = lda_multicore_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_multicore_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore_model, texts=df3['essays'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use gensim and the following three variables, then you can visualize topics & keywords with the code below.\n",
    "\n",
    "    lda_model:    this is an LDA model generated by gensim.models.ldamodel.LdaModel()\n",
    "    id2word:      this is the dictionary term IDs from corpora.Dictionary()\n",
    "    corpus:       this is the collection of \"documents\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics-keywords\n",
    "lda_model=lda_multicore_model\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 5:  Make an LDA topic model for the DESCRIPTIONS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Part 5 is worth 5 points (the value of 5 individual problems).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same K (and any other hyperparameters from Part 4), recompute a model for Descriptions. Compare the two sets of results. Do they vary? How? Why? Explain what you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create Dictionary\n",
    "id2word_description = corpora.Dictionary(df3['description'])\n",
    "\n",
    "# Create Corpus\n",
    "texts_description = df3['description']\n",
    "# Term Document Frequency\n",
    "corpus_description = [id2word.doc2bow(text) for text in texts_description]\n",
    "\n",
    "# View unique id for each word in the essay\n",
    "print(corpus_description[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import time\n",
    "start_time = time.time()\n",
    "##\n",
    "## Build Multicore LDA\n",
    "lda_multicore_model_d = gensim.models.ldamulticore.LdaMulticore(corpus_description, num_topics = 7, \n",
    "                                                                id2word_description,random_state=100,passes=10)\n",
    "# Saving trained model\n",
    "lda_multicore_model_d.save('LDA_NYT_multicore_d')\n",
    "# Loading trained model\n",
    "lda_multicore_model_d = gensim.models.ldamodel.LdaModel.load('LDA_NYT_multicore_d')\n",
    "## Print time taken to train the model\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 7 topics\n",
    "print(lda_multicore_model_d.print_topics())\n",
    "doc_lda_d = lda_multicore_model_d[corpus_description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_multicore_model_d.log_perplexity(corpus_description))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore_model_d, texts=df3['description'], dictionary=id2word_description, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topics-keywords\n",
    "lda_model=lda_multicore_model_d\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus_description, id2word_description)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 6:  Use TextHero and help to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: This is worth 5 points (the value of 5 individual problems).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TextHero](https://texthero.org/) is an opensource project developed by a student from the [TIS Lab of Prof. Younge](www.epfl.ch/labs/tis). Go to the [GIT repository for TextHero](https://github.com/jbesomi/texthero), install the package, review the documentation, and if you are impressed by the package - give it a star and tell others! (Not required)\n",
    "\n",
    "Once you understand TextHero, then use the package to re-implement major portions of Part 3 of this assignment that you completed above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install texthero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=copy.copy(merged_df_textual) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data2.columns:\n",
    "    data2[column] = data2[column] .pipe(hero.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['tfidf'] = (\n",
    "    hero.tfidf(data2['essays'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['pca'] = hero.pca(data2['tfidf'])\n",
    "hero.scatterplot(\n",
    "    df, \n",
    "    col='pca', \n",
    "    color='topic', \n",
    "    title=\"PCA BBC Sport news\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: This is worth 5 points (the value of 5 individual problems).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenSourcve packages rely on the community of users to help them grow and improve. Review the [contributing file](https://github.com/jbesomi/texthero/blob/master/CONTRIBUTING.md) for Text Hero and then identify a portion of the documentation that you feel could be improves. Edit/write 1 paragraph of documentation for the package that you believe would improve it. Copy that paragraph in below (into this notebook) so that it can be graded. And - if you think your contribution would truly help the project, please learn how to use git to suggest the change (a pull request) to the manager of the repository (Jonathan Besomi). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation \n",
    "\n",
    "texthero.representation.nmf\n",
    "\n",
    "nmf(s, n_components=2)\n",
    "\n",
    "    Perform non-negative matrix factorization.\n",
    "\n",
    "Find two non-negative matrices (W, H) whose product approximates the non-negative matrix X. \n",
    "This factorization can be used for example for dimensionality reduction, source separation or topic extraction.\n",
    "\n",
    "Parameters\n",
    "\n",
    "    s: Pandas Series\n",
    "    n_components: Int. Default is 2.\n",
    "        Number of components to keep. If n_components is not set or None, all components are kept.\n",
    "\n",
    "Examples\n",
    "\n",
    "import texthero as hero\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([\"Sentence one\", \"Sentence two\"])\n",
    "\n",
    "custom_pipeline = [preprocessing.lowercase,\n",
    "                   preprocessing.remove_whitespace]\n",
    "s= hero.clean(s, custom_pipeline)\n",
    "s_tf_idf = hero.tfidf(s)\n",
    "pca=hero.nmf(s_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for pca\n",
    "\n",
    "Example:\n",
    "    \n",
    "import texthero as hero\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([\"Sentence one\", \"Sentence two\"])\n",
    "\n",
    "custom_pipeline = [preprocessing.lowercase,\n",
    "                   preprocessing.remove_whitespace]\n",
    "                   \n",
    "s= hero.clean(s, custom_pipeline)\n",
    "\n",
    "s_tf_idf = hero.tfidf(s)\n",
    "\n",
    "pca=hero.pca(s_tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
